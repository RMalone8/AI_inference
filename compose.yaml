services:
  ollama-server-llava-phi:
    image: ollama/ollama:latest
    volumes:
      - ollama_models:/root/.ollama
    restart: unless-stopped

  ollama-server-moondream:
    image: ollama/ollama:latest
    volumes:
      - ollama_models:/root/.ollama
    restart: unless-stopped

  ollama-stats:
    build:
      context: .
      dockerfile: Dockerfile.stats
    depends_on:
      - ollama-server-llava-phi
      - ollama-server-moondream
    volumes:
      - /run/podman/podman.sock:/tmp/podman.sock

  ollama-client-llava-phi:
    build:
      context: .
      dockerfile: Dockerfile.client
    depends_on:
      - ollama-server-llava-phi
    environment:
      - OLLAMA_HOST=http://ollama-server-llava-phi:11434
      - CLIENT_TYPE=llava-phi3:3.8b 

  ollama-client-moondream:
      build:
        context: .
        dockerfile: Dockerfile.client
      depends_on:
        - ollama-server-moondream
      environment:
        - OLLAMA_HOST=http://ollama-server-moondream:11434
        - CLIENT_TYPE=moondream:1.8b

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    expose:
      - 9100
  
  grafana:
    build:
      context: .
      dockerfile: Dockerfile.grafana
    ports:
      - "3000:3000"

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      #- prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"


volumes:
  ollama_models:
  #prometheus_data: {}
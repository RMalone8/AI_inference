# /// script
# dependencies = [
#   "pydantic",
#   "langchain[openai]",
#   "requests",
#   "prometheus_client",
# ]
# ///

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

from pydantic import BaseModel, Field
from prometheus_client import start_http_server, Gauge

import base64
from pathlib import Path

import os
import time
import requests

ITER_NO = 5

class Animal(BaseModel):
    species: str = Field(description="The species of the animal")
    breed: str = Field(description="The breed of the animal")
    features: list[str] = Field(description="List of features used in classification")

SYSTEM = SystemMessage(
    "You are an expert animal recognition AI. Your task is to analyze images and accurately identify the species (e.g., dog, cat, bird) and, when possible, the specific breed (e.g., Golden Retriever, Siamese, Persian). If the breed is unclear, provide the most likely options or state that the breed is unknown. Be precise, use common breed names, and note any distinctive physical features that support your classification."  # generated by chatgpt
)

def main():

    start_http_server(7000)

    model_path = os.environ.get("CLIENT_PATH", "Cannot Find Model Path")
    model_name = os.environ.get("CLIENT_NAME", "Cannot Find Model Name")
    model_iter = os.environ.get("CLIENT_ITER", "Cannot Find Model Iter")
    host = os.environ.get("HOST", "Cannot Find Host")
    temp = os.environ.get("TEMP", "Cannot Find Temp")

    client_running = Gauge(f'client_running_{model_name}_{int(model_iter)}', 'Client is active')
    times_per_iter = []
    token_per_sec_per_iter = []
    avg_time_per_iter = Gauge(f'client_avg_time_per_iter_{model_name}_{int(model_iter)}', 'Average time taken for client to run per iteration')
    avg_token_per_sec_per_iter = Gauge(f'client_avg_token_per_sec_per_iter_{model_name}_{int(model_iter)}', 'Average tokens per second per iteration')
    print(f"-CLIENT CONFIGURATION-")
    print(f"Model Name: {model_path}")
    print(f"Host: {host}")
    print(f"API Base: {host}/v1")
    print("=" * 30)

    print("Waiting for server to be ready...")
    max_retries = 30
    for attempt in range(max_retries):
        try:
            response = requests.get(f"{host}/v1/models", timeout=10)
            if response.status_code == 200:
                print("Server is ready!")
                break
        except requests.exceptions.RequestException as e:
            print(f"Attempt {attempt + 1}/{max_retries}: Server not ready yet ({e})")
            time.sleep(10)
    else:
        print("Server failed to become ready after maximum retries")
        return

    model = ChatOpenAI(
        model=model_path,
        temperature=float(temp),
        base_url=f"{host}/v1",
        api_key="dummy",
    ) # .with_structured_output(Animal)

    client_running.set(1)
    for i in range(ITER_NO):
        r = requests.get('https://cataas.com/cat')
        r.raise_for_status()
        print(f"ITER: {i}")
        print(f"{model_path} is asked: ")
        print("Describe the breed and species of the animal in this image, return as JSON")
        print("The model returns: ")
        start_time_per_iter = time.time()
        response = model.invoke(
                [
                    SYSTEM,
                    HumanMessage(
                        content=[
                            {
                                "type": "text",
                                "text": "Describe the breed and species of the animal in this image, return as JSON",
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64.b64encode(r.content).decode()}"
                                }
                            },
                        ]
                    ),
                ]
            )
        end_time_per_iter = time.time()
        print(response)

        output_tokens = response.usage_metadata['output_tokens']
        time_per_iter = end_time_per_iter - start_time_per_iter
        token_per_sec = output_tokens / time_per_iter

        times_per_iter.append(time_per_iter)
        token_per_sec_per_iter.append(token_per_sec)
        print(f"Time taken for iteration {i}: {end_time_per_iter - start_time_per_iter}")
        print(f"Token per second for iteration {i}: {token_per_sec}")
    
    print(f"Times per iter: {times_per_iter}")
    print(f"Average time per iter: {sum(times_per_iter) / len(times_per_iter)}")
    client_running.set(0)
    avg_time_per_iter.set(round(sum(times_per_iter) / len(times_per_iter), 4))
    avg_token_per_sec_per_iter.set(round(sum(token_per_sec_per_iter) / len(token_per_sec_per_iter), 4))

    time.sleep(10) # allow time forprometheus to collect data

if __name__ == "__main__":
    main()
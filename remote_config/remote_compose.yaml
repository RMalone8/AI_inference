services:
  ollama-server:
    image: ${OLLAMA_IMAGE}
    container_name: ollama-server-${MODEL_NAME}
    volumes:
      - ${SERV_VOL}
      #- ollama_models:/root/.ollama
      #- ollama:/data/models/ollama

    tty: true  # required for jetson ollama base image, since it's using bash as its entrypoint without an open stdin bash would exit
    stdin_open: true  # required for jetson ollama base image
    restart: unless-stopped

  ollama-client:
    build:
      context: .
      dockerfile: Dockerfile.client
    depends_on:
      - ollama-server
    container_name: ollama-client-${MODEL_NAME}
    environment:
      - OLLAMA_HOST=http://ollama-server-${MODEL_NAME}:11434
      - CLIENT_TYPE=${MODEL_SPECS}
    tty: true

  ollama-stats:
    image: quay.io/navidys/prometheus-podman-exporter
    depends_on:
      - ollama-server
    container_name: ollama-stats
    environment:
      - CONTAINER_HOST=unix:///tmp/podman.sock

    userns_mode: "keep-id:uid=65534" # -> comment this out to use the jetson machine
 
    security_opt:
      - "label=disable"
    volumes:
      - ${HOST_SOCK}:/tmp/podman.sock
      #- /run/user/1001/podman/podman.sock:/tmp/podman.sock
      #- /run/podman/podman.sock:/tmp/podman.sock
    ports:
      - "8000:9882"

  node-exporter:
    image: docker.io/prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    network_mode: host
    pid: host
    volumes:
      - /:/host:ro,rslave # jetson
    command:
      - '--path.rootfs=/host' # jetson
      - '--no-collector.thermal_zone'

  prometheus:
    build:
      context: .
      dockerfile: Dockerfile.promremote
    container_name: prometheus
    restart: unless-stopped
      #- ./prometheus.yml:/etc/prometheus/prometheus.yml
      #- prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      #- '--log.level=error'

volumes:

  ollama_models:

  #prometheus_data: {}

x-podman:
  in_pod: false
# for the volumes, when using armchair use ollama_models. When using the jetson use ollama
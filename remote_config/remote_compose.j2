services:
  server:
    container_name: {{runtime}}-server-${MODEL_NAME}{% if gpu %}-gpu{% endif %}
{% if runtime == 'vllm' and not gpu %}
    build:
      context: .
      dockerfile: Dockerfile.vllmcpu
    privileged: true
{% else %}
    image: ${SERVER_IMAGE}
    volumes:
      - ${SERV_VOL}
{% endif %}
{% if runtime == 'ollama' %}
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    environment:
      - OLLAMA_CONTEXT_LENGTH={{ context }}
{% elif runtime == 'vllm' %}
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    environment:
      - HF_TOKEN=${HF_TOKEN}
{% endif %}
{% if machine == 'jetson' and gpu %}
    devices:
      - "nvidia.com/gpu=all"
{% endif %}
    tty: true  # required for jetson ollama base image, since it's using bash as its entrypoint without an open stdin bash would exit
    stdin_open: true  # required for jetson ollama base image
    restart: unless-stopped
{% if runtime == 'vllm' %}
    command:
      - "vllm"
      - "serve"
      - "${MODEL_PATH}"
{% if context %}
      - "--max-model-len"
      - "{{ context }}"
{% endif %}
{% if not gpu %}
      - "--dtype"
      - "float16"
{% endif %}
{% endif %}

{% if not webui %}
  client:
    build:
      context: .
      dockerfile: Dockerfile.client
    depends_on:
      server:
        condition: service_healthy
    container_name: {{runtime}}-client-${MODEL_NAME}{% if gpu %}-gpu{% endif %}
    environment:
{% if runtime == 'ollama' %}
      - HOST=http://{{runtime}}-server-${MODEL_NAME}{% if gpu %}-gpu{% endif %}:11434
{% elif runtime == 'vllm' %}
      - HOST=http://{{runtime}}-server-${MODEL_NAME}{% if gpu %}-gpu{% endif %}:8000
{% endif %}
      - CLIENT_PATH=${MODEL_PATH}
      - CLIENT_NAME=${MODEL_NAME}
      - TEMP={{temp}}
    tty: true
{% endif %}

  container-stats:
    image: quay.io/navidys/prometheus-podman-exporter
    depends_on:
      - server
    container_name: container-stats
    environment:
      - CONTAINER_HOST=unix:///tmp/podman.sock
{% if machine == 'armchair' %}
    userns_mode: "keep-id:uid=65534" # -> comment this out to use the jetson machine
{% endif %} 
    security_opt:
      - "label=disable"
    volumes:
      - ${HOST_SOCK}:/tmp/podman.sock
    ports:
      - "9882:9882"

  node-exporter:
    image: docker.io/prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    network_mode: host
    pid: host
    volumes:
      - /:/host:ro,rslave # jetson
    command:
      - '--path.rootfs=/host' # jetson
      - '--no-collector.thermal_zone'
{% if machine == 'jetson' %}
# jetson exporter
  jetson_stats_node_exporter:
    build:
      context: .
      dockerfile: Dockerfile.jsnode
    container_name: jetson_stats_node_exporter
    restart: unless-stopped
    depends_on:
      - jetson_stats
    volumes:
      - "/run:/run"

  jetson_stats:
    build:
      context: .
      dockerfile: Dockerfile.jstats
    container_name: jetson_stats
    restart: unless-stopped
    volumes:
      - "/run:/run"
      - "/etc/fstab:/etc/fstab:ro"
      - "/sys:/sys"
    pid: host
    privileged: true
{% endif %}
  prometheus:
    build:
      context: .
      dockerfile: Dockerfile.promremote
    container_name: prometheus
    restart: unless-stopped
      #- ./prometheus.yml:/etc/prometheus/prometheus.yml
      #- prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      #- '--log.level=error'

volumes:
{% if machine == 'jetson' and runtime == 'ollama' %}
  ollama:
    external: true
{% elif machine == 'jetson' and runtime == 'vllm' %}
  vllm_cache:
{% elif machine == 'armchair' and runtime == 'ollama' %}
  ollama_models:
{% elif machine == 'armchair' and runtime == 'vllm' %}
  vllm_cache:
{% endif %}
  #prometheus_data: {}

x-podman:
  in_pod: false